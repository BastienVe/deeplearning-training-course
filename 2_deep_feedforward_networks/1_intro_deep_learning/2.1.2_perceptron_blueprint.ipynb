{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"item\">\n",
    "    <img src=\"figures/perceptron_blueprint.png\" alt=\"perceptron_blueprint\" width=\"600px\"/>\n",
    "</div>\n",
    "\n",
    "In the perceptron algorithm, the inputs are multiplied by their corresponding weights, and the results of these products are added up. The resulting number, the net input, is then checked against the threshold. If it’s above the threshold, then the perceptron “fires” and outputs a 1, otherwise it outputs a 0 (this is called the Step function).\n",
    "\n",
    "\n",
    "<div class=\"item\">\n",
    "    <img src=\"figures/perceptron_step_1.png\" alt=\"perceptron_step_1\" width=\"600px\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"item\">\n",
    "    <img src=\"figures/perceptron_step_2.png\" alt=\"perceptron_step_2\" width=\"600px\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"item\">\n",
    "    <img src=\"figures/perceptron_step_3.png\" alt=\"perceptron_step_3\" width=\"600px\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"item\">\n",
    "    <img src=\"figures/perceptron_step_4.png\" alt=\"perceptron_step_4\" width=\"600px\"/>\n",
    "</div>\n",
    "\n",
    "The secret sauce of the perceptron, however, is not the method by which it calculates an output, but how it learns from its mistakes and updates its weights to improve performance. It does this by first comparing its output (a 1 or 0) against the actual outcome in the training data. Next, it subtracts its predicted outcome from the real outcome—the difference representing the training “error.” Then, it multiplies the error by a learning rate (a number between 0 and 1) that determines the extent to which new information should impact the existing weights. A low learning rate means less stock will be put into the new information it learns, and a high number means that new information will more quickly override older information. (This similar to the learning rate we discussed in the Q-Learning algorithm in the last article.) The resulting number represents the amount the weights should be adjusted, or the “change-in-weights.”\n",
    "\n",
    "\n",
    "<div class=\"item\">\n",
    "    <img src=\"figures/perceptron_step_5.png\" alt=\"perceptron_step_5\" width=\"600px\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"item\">\n",
    "    <img src=\"figures/perceptron_step_6.png\" alt=\"perceptron_step_6\" width=\"600px\"/>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"item\">\n",
    "    <img src=\"figures/perceptron_step_7.png\" alt=\"perceptron_step_7\" width=\"600px\"/>\n",
    "</div>\n",
    "\n",
    "Finally, the perceptron adds the change-in-weights to each one of the existing weights, and the perceptron now has an updated set of weights that yield a more accurate outcome. This is how the perceptron learns, by using its weights to try to calculate an outcome, checking the outcome against the actual result, and adjusting its weights accordingly. The more training data the perceptron is fed, the more this process repeats itself, and the more accurate the perceptron’s output becomes.\n",
    "\n",
    "\n",
    "<div class=\"item\">\n",
    "    <img src=\"figures/perceptron_step_8.png\" alt=\"perceptron_step_8\" width=\"600px\"/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
